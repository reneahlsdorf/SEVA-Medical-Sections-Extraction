{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section Extraction Notebook (BigQuery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook extracts sections from MIMIC based on the trigger text file you've unpacked in `../data` in the clone of this repo. You need to create a project in your Google Cloud  / BigQuery account as describe over here.\n",
    "\n",
    "Please note down your **project id** and the **table name** you would like to save the extracted sections to in BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_PROJECT_ID = \"hst-953-2019\"\n",
    "GOOGLE_CLIENT_SECRET_FILE = \"/Users/reneahlsdorf/Downloads/client_secret_255053072421-h3okuh4a17ruuuffjriv09l6e3n6lslo.apps.googleusercontent.com.json\" # \"<PATH TO CLIENT FILE>\"\n",
    "BIGQUERY_TARGET_TABLE = \"non_adherence.all_sectioned_new_trigger_v10_2022_restore_2\"\n",
    "DATASETNAME = \"mimiciii_noteevents\"\n",
    "TRIGGERS_PATH = \"../data/triggers.txt\"\n",
    "JOBS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import sys, os, math\n",
    "import pandas as pd\n",
    "from google_auth_oauthlib import flow\n",
    "from google.cloud import bigquery\n",
    "import warnings\n",
    "\n",
    "from db import mimic\n",
    "from sectioning import sectioning\n",
    "from data import triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup stuff\n",
    "mp.set_start_method('fork')\n",
    "sys.path.insert(0, \"../src\")\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIMIC Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appflow = flow.InstalledAppFlow.from_client_secrets_file(\n",
    "    GOOGLE_CLIENT_SECRET_FILE, scopes=[\"https://www.googleapis.com/auth/bigquery\"]\n",
    ")\n",
    "appflow.run_console()\n",
    "credentials = appflow.credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client(GOOGLE_PROJECT_ID, credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_ids = mimic.get_row_ids(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching & Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_filepath = TRIGGERS_PATH\n",
    "triggers, phrase_to_group, allphrases = triggers.process_trigger_file(trigger_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "chunk = math.ceil(note_ids.shape[0] / JOBS)\n",
    "\n",
    "super_block_size = 1000\n",
    "super_block_cnt = math.ceil(len(note_ids) / super_block_size)\n",
    "chunk = math.ceil(super_block_size / JOBS)\n",
    "range_list = range(0, super_block_size, chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitting_section_thread(client, idx_start, idx_end):\n",
    "      returned_sections = mimic.get_note_texts(client, note_ids[idx_start:idx_end])\n",
    "      missed = []\n",
    "      \n",
    "      ret_val = sectioning.section_notes(list(returned_sections.text.values), list(returned_sections.row_id.values), missed, allphrases, phrase_to_group)\n",
    "      print(\"Missed (%d - %d): %d\" % (idx_start, idx_end, len(missed)))\n",
    "      return returned_sections, ret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_thread(index, offset):\n",
    "  import warnings\n",
    "  warnings.filterwarnings('ignore')\n",
    "\n",
    "  client = bigquery.Client(GOOGLE_PROJECT_ID, credentials=credentials)\n",
    "  indexes = range_list[index]\n",
    "  \n",
    "  if offset + indexes >= len(note_ids):\n",
    "      cols = ['row_id', 'extracted_section_title', 'section_group', 'section_text', 'start', 'end', 'index', 'section_id']\n",
    "      section_df = pd.DataFrame([], columns=[_ for _ in cols])\n",
    "      return [section_df, []]\n",
    "\n",
    "  sections, missed = splitting_section_thread(client, offset + indexes, min(len(note_ids), offset + min(indexes + chunk, super_block_size)))\n",
    "\n",
    "  return sections, missed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing superbloc 1/2084\n",
      "Missed (500 - 1000): 416\n",
      "Missed (0 - 500): 38\n",
      "Exporting 1000 sections to GBQ...\n",
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=725825577420-unm2gnkiprugilg743tkbig250f4sfsj.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fbigquery&state=DRv9iwdtFtVfQFaA4ECSF24WxR9BwK&prompt=consent&access_type=offline\n"
     ]
    }
   ],
   "source": [
    "# row_ids.shape[0]\n",
    "\n",
    "pool = mp.Pool(JOBS)\n",
    "all_returns = []\n",
    "for _s in range(super_block_cnt):\n",
    "  if _s > 0:\n",
    "    break\n",
    "  \n",
    "  print('Now processing superbloc {}/{}'.format(_s+1, (super_block_cnt)))\n",
    "  returns = pool.starmap(run_thread, [(_i,_s * super_block_size) for _i in range(JOBS)])\n",
    "  all_returns.append([_s, returns])\n",
    "  df = pd.concat([_[0] for _ in returns], axis=0)\n",
    "  print('Exporting {} sections to GBQ...'.format(df.shape[0]))\n",
    "\n",
    "  df.to_gbq(BIGQUERY_TARGET_TABLE, project_id=GOOGLE_PROJECT_ID, if_exists='append',)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a23884a3ba87012f90290ecb1563e90aff7d3705f7bcb5936b2155f67c0e0220"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit ('seva')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
